{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "medical_specialty_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luca-martial/medical-specialty/blob/main/medical_specialty_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9cgIX-NmI4G"
      },
      "source": [
        "## Medical Specialty Prediction with Spark NLP\n",
        "\n",
        "The goal of this project was to predict medical specialties (surgery, internal medicine, medical records, other) based on a corpus of 4999 medical transcriptions using Spark NLP. The corpus was scraped by [Tara Boyle](https://github.com/terrah27) from a [Transcribed Medical Transcription Sample Reports and Examples website](https://mtsamples.com/) and published on [Kaggle](https://www.kaggle.com/tboyle10/medicaltranscriptions). The version used in this project was compiled by [Carlos Salgado](https://github.com/socd06) for Natural Language Processing using the scraped corpus and custom-generated clinical stop words and vocabulary. This compiled version was published on [GitHub](https://github.com/socd06/medical-nlp) and is free to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81xX4FYSovpb"
      },
      "source": [
        "## Set-Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlQPMy6kl_Ez"
      },
      "source": [
        "### Installing SparkNLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "P2Vg-VepNRNw",
        "outputId": "b1ec4d5e-0b34-4220-a32c-a2d8ce6f35ea"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e22c0d5-3939-471e-81a8-613181adc43c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8e22c0d5-3939-471e-81a8-613181adc43c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spark_nlp_for_healthcare_v3.3-1.json to spark_nlp_for_healthcare_v3.3-1.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWos3ASBBKF8",
        "outputId": "369fbb3c-c277-4ce0-bae6-0520523e0ac5"
      },
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 64 kB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 55.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 59.3 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 133 kB 26.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "U40sDKOHNYe9",
        "outputId": "59c41c8a-3cb2-4993-d03e-3ad5b0abfe55"
      },
      "source": [
        "# Import libraries and start session\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "import sparknlp\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", \n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"} \n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'], \n",
        "                           gpu=True, \n",
        "                           params=params)\n",
        "\n",
        "spark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.3.0\n",
            "Spark NLP_JSL Version : 3.3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://fc2e2113f7fc:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fddfb13ac10>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXs5Z5wgMe4o"
      },
      "source": [
        "# Import auxiliary libraries\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from pyspark.sql.functions import explode\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.feature import StringIndexer, CountVectorizer, HashingTF, IDF"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgkQ9G5VkUtx"
      },
      "source": [
        "### Reading in Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0LXuIzSOek1"
      },
      "source": [
        "# Get datasets\n",
        "! wget -q https://raw.githubusercontent.com/socd06/medical-nlp/master/data/train.csv\n",
        "! wget -q https://raw.githubusercontent.com/socd06/medical-nlp/master/data/test.csv"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS4FXeWOfRy1"
      },
      "source": [
        "labelDict = {'1':'Surgery', '2':'Medical Records', '3':'Internal Medicine', '4':'Other'}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhNrz4j1AUHf"
      },
      "source": [
        "trainDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"train.csv\") \\\n",
        "      .replace(labelDict, subset=['label'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL-1j29m12tc",
        "outputId": "0f442362-f9f7-403c-c64c-dabf19cfcafa"
      },
      "source": [
        "trainDataset.printSchema()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTmouQW7GRM2",
        "outputId": "456df8fc-785c-4be6-dc7f-0460326ebe6f"
      },
      "source": [
        "trainDataset.show(10, truncate=50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------------------------------+--------------------------------------------------+\n",
            "|            label|                          description|                                              text|\n",
            "+-----------------+-------------------------------------+--------------------------------------------------+\n",
            "|  Medical Records|                         2-D Doppler |2-D STUDY,1. Mild aortic stenosis, widely calci...|\n",
            "|          Surgery|                         Gastroscopy |PREOPERATIVE DIAGNOSES: , Dysphagia and esophag...|\n",
            "|  Medical Records|       Three-Week Postpartum Checkup |CHIEF COMPLAINT:,  The patient comes for three-...|\n",
            "|          Surgery|             Radiofrequency Ablation |PROCEDURE: , Bilateral L5, S1, S2, and S3 radio...|\n",
            "|  Medical Records|               Discharge Summary - 3 |DISCHARGE DIAGNOSES:,1. Chronic obstructive pul...|\n",
            "|Internal Medicine| Heart Catheterization & Angiography |INDICATION:,  Coronary artery disease, severe a...|\n",
            "|  Medical Records|                Gen Med Consult - 21 |SUBJECTIVE:,  The patient is a 2-year-old littl...|\n",
            "|  Medical Records|   Neuropsychological Evaluation - 1 |REASON FOR EVALUATION: , The patient is a 37-ye...|\n",
            "|  Medical Records| MRI Brain -  Meningioma (Olfactory) |CC:, Progressive visual loss.,HX:, 76 y/o male ...|\n",
            "|Internal Medicine|                      Knee Injection |The patient was told that the injection may cau...|\n",
            "+-----------------+-------------------------------------+--------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXLLrcaBPDkI",
        "outputId": "8ccccd62-106c-42df-83b1-41b8a5efbe8c"
      },
      "source": [
        "trainDataset.groupBy(\"label\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|            label|count|\n",
            "+-----------------+-----+\n",
            "|          Surgery| 1442|\n",
            "|  Medical Records| 1126|\n",
            "|Internal Medicine| 1040|\n",
            "|            Other|  891|\n",
            "+-----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tY3LrNGStPm"
      },
      "source": [
        "testDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"test.csv\") \\\n",
        "      .replace(labelDict, subset=['label'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE7gLVSwStVd",
        "outputId": "84c00757-ecdf-4879-9d14-bf4a5cdebd1a"
      },
      "source": [
        "testDataset.show(10, truncate=50)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------------------------------------+--------------------------------------------------+\n",
            "|            label|                                description|                                              text|\n",
            "+-----------------+-------------------------------------------+--------------------------------------------------+\n",
            "|  Medical Records|      Hemiarthroplasty - Discharge Summary |ADMISSION DIAGNOSES:  ,Fracture of the right fe...|\n",
            "|          Surgery|                        Plantar Fasciotomy |PREOPERATIVE DIAGNOSIS:,  Plantar fascitis, lef...|\n",
            "|  Medical Records|      Hysterectomy - Discharge Summary - 2 |ADMISSION DIAGNOSIS: , Microinvasive carcinoma ...|\n",
            "|            Other|        Total Knee Arthoplasty - Right - 1 |PREOPERATIVE DIAGNOSIS:,  Severe degenerative j...|\n",
            "|          Surgery|         Breast Radiation Therapy Followup |DIAGNOSIS: , Left breast adenocarcinoma stage T...|\n",
            "|            Other|                         Hamstring Release |PREOPERATIVE DIAGNOSIS: , Autism with bilateral...|\n",
            "|            Other| Ruptured Globe Repair - Sclera and Limbus |PREOPERATIVE DIAGNOSIS: , Ruptured globe with u...|\n",
            "|Internal Medicine|                   Mediastinal Exploration |TITLE OF OPERATION:,  Mediastinal exploration a...|\n",
            "|Internal Medicine|                   Normal ROS Template - 5 |REVIEW OF SYSTEMS,GENERAL:  Negative weakness, ...|\n",
            "|          Surgery|          Total Abdominal Hysterectomy - 2 |PREOPERATIVE DIAGNOSES:,1.  Enlarged fibroid ut...|\n",
            "+-----------------+-------------------------------------------+--------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15gV5E7lSuEk",
        "outputId": "d3fb3ab5-61f5-4a1a-e873-bb66e9c1e0a8"
      },
      "source": [
        "testDataset.groupBy(\"label\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|            label|count|\n",
            "+-----------------+-----+\n",
            "|          Surgery|  198|\n",
            "|Internal Medicine|  109|\n",
            "|  Medical Records|  102|\n",
            "|            Other|   91|\n",
            "+-----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxKZngGPo8JP"
      },
      "source": [
        "The classes are quite imbalanced on both the training and test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1sGjg1ziO93"
      },
      "source": [
        "## DL Classifiers with Sentence Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJu03s0TUCLO"
      },
      "source": [
        "### DL Classification with Universal Sentence Encoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9WK0cvhBsiP",
        "outputId": "49d9747f-c4f3-40c5-d2d5-158cf713e2a3"
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "use = UniversalSentenceEncoder.pretrained()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "classifierdl = ClassifierDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setMaxEpochs(10)\\\n",
        "    .setLr(0.001)\\\n",
        "    .setBatchSize(64)\\\n",
        "    .setEnableOutputLogs(True)\n",
        "\n",
        "use_clf_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        use,\n",
        "        classifierdl\n",
        "    ])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBQDo_0xBstz"
      },
      "source": [
        "use_pipelineModel = use_clf_pipeline.fit(trainDataset)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Urb6f78Gt5O",
        "outputId": "7316a71b-e1b9-49d3-df3c-72889da74b6a"
      },
      "source": [
        "log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n",
        "\n",
        "with open(\"/root/annotator_logs/\"+log_file_name, \"r\") as log_file :\n",
        "    print(log_file.read())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started - epochs: 10 - learning_rate: 0.001 - batch_size: 64 - training_examples: 4499 - classes: 4\n",
            "Epoch 0/10 - 0.61s - loss: 88.89431 - acc: 0.506344 - batches: 71\n",
            "Epoch 1/10 - 0.31s - loss: 86.799675 - acc: 0.53000474 - batches: 71\n",
            "Epoch 2/10 - 0.30s - loss: 86.150055 - acc: 0.5322369 - batches: 71\n",
            "Epoch 3/10 - 0.31s - loss: 85.857346 - acc: 0.53357613 - batches: 71\n",
            "Epoch 4/10 - 0.30s - loss: 85.60088 - acc: 0.5342458 - batches: 71\n",
            "Epoch 5/10 - 0.29s - loss: 85.382484 - acc: 0.53491545 - batches: 71\n",
            "Epoch 6/10 - 0.44s - loss: 85.17749 - acc: 0.53580827 - batches: 71\n",
            "Epoch 7/10 - 0.33s - loss: 84.98671 - acc: 0.5360315 - batches: 71\n",
            "Epoch 8/10 - 0.29s - loss: 84.81304 - acc: 0.53692436 - batches: 71\n",
            "Epoch 9/10 - 0.28s - loss: 84.65803 - acc: 0.53692436 - batches: 71\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrDlYMlQbE8T",
        "outputId": "9e297902-3553-461a-ee56-6d9b5a7fc544"
      },
      "source": [
        "# Evaluate model on test set\n",
        "use_df = use_pipelineModel.transform(testDataset).select('label', 'text', 'class.result').toPandas()\n",
        "use_df['result'] = use_df['result'].apply(lambda x: str(x[0])).replace(labelDict)\n",
        "print(classification_report(use_df.label, use_df.result))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Internal Medicine       0.33      0.03      0.05       109\n",
            "  Medical Records       0.41      0.90      0.57       102\n",
            "            Other       0.00      0.00      0.00        91\n",
            "          Surgery       0.65      0.88      0.75       198\n",
            "\n",
            "         accuracy                           0.54       500\n",
            "        macro avg       0.35      0.45      0.34       500\n",
            "     weighted avg       0.41      0.54      0.42       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA6nNjob6d-U"
      },
      "source": [
        "### DL Classification with BERT Sentence Embeddings (Compact Version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xRqKnxhmHpr",
        "outputId": "988e8818-948f-4355-d9a9-5ffa1b9a87db"
      },
      "source": [
        "bert_sent = BertSentenceEmbeddings.pretrained(\"sent_small_bert_L8_512\")\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "bert_sent_clf_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        bert_sent,\n",
        "        classifierdl\n",
        "    ])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent_small_bert_L8_512 download started this may take some time.\n",
            "Approximate size to download 149.1 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k636WCQ9y7b"
      },
      "source": [
        "bert_sent_pipelineModel = bert_sent_clf_pipeline.fit(trainDataset)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWEShs7Z9zFS",
        "outputId": "33f6b83c-3357-4b95-c9e6-320ce7287147"
      },
      "source": [
        "# Evaluate model on test set\n",
        "bert_sent_df = bert_sent_pipelineModel.transform(testDataset).select('label', 'text', 'class.result').toPandas()\n",
        "bert_sent_df['result'] = bert_sent_df['result'].apply(lambda x: str(x[0])).replace(labelDict)\n",
        "print(classification_report(bert_sent_df.label, bert_sent_df.result))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Internal Medicine       0.40      0.16      0.23       109\n",
            "  Medical Records       0.41      0.84      0.55       102\n",
            "            Other       0.00      0.00      0.00        91\n",
            "          Surgery       0.65      0.81      0.73       198\n",
            "\n",
            "         accuracy                           0.53       500\n",
            "        macro avg       0.37      0.45      0.37       500\n",
            "     weighted avg       0.43      0.53      0.45       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSutOPJiH5gU"
      },
      "source": [
        "### DL Classification with BioBERT (Clnical) Sentence Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h55_agOvH9yk",
        "outputId": "5e8798e3-ee47-426e-a34d-5177b6b3a5d5"
      },
      "source": [
        "biobert_clin = BertSentenceEmbeddings.pretrained(\"sent_biobert_clinical_base_cased\", \"en\")\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "biobert_clin_clf_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        biobert_clin,\n",
        "        classifierdl\n",
        "    ])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent_biobert_clinical_base_cased download started this may take some time.\n",
            "Approximate size to download 386.6 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnYtRLHcJ0us"
      },
      "source": [
        "biobert_clin_pipelineModel = biobert_clin_clf_pipeline.fit(trainDataset)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0llyyGuCJ0us",
        "outputId": "27e53953-36f8-48d7-85a3-fbf1a7382788"
      },
      "source": [
        "# Evaluate model on test set\n",
        "biobert_clin_df = biobert_clin_pipelineModel.transform(testDataset).select('label', 'text', 'class.result').toPandas()\n",
        "biobert_clin_df['result'] = biobert_clin_df['result'].apply(lambda x: str(x[0])).replace(labelDict)\n",
        "print(classification_report(biobert_clin_df.label, biobert_clin_df.result))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Internal Medicine       0.44      0.14      0.21       109\n",
            "  Medical Records       0.43      0.87      0.57       102\n",
            "            Other       0.00      0.00      0.00        91\n",
            "          Surgery       0.65      0.84      0.73       198\n",
            "\n",
            "         accuracy                           0.54       500\n",
            "        macro avg       0.38      0.46      0.38       500\n",
            "     weighted avg       0.44      0.54      0.45       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrbQzBjfH-33"
      },
      "source": [
        "### DL Classification with BioBERT (MedNLI) Sentence Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYGbXj09IBT8",
        "outputId": "04f26e79-bb14-4791-b0db-be88de640fe2"
      },
      "source": [
        "biobert_med = BertSentenceEmbeddings.pretrained(\"sbiobert_base_cased_mli\",\"en\",\"clinical/models\")\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "biobert_med_clf_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        biobert_med,\n",
        "        classifierdl\n",
        "    ])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sbiobert_base_cased_mli download started this may take some time.\n",
            "Approximate size to download 384.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5VbHeoGJ_qT"
      },
      "source": [
        "biobert_med_pipelineModel = biobert_med_clf_pipeline.fit(trainDataset)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_-fW4T5J_qT",
        "outputId": "5665d53f-7858-4b9f-8298-e7f21ec6c6ef"
      },
      "source": [
        "log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n",
        "\n",
        "with open(\"/root/annotator_logs/\"+log_file_name, \"r\") as log_file :\n",
        "    print(log_file.read())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started - epochs: 10 - learning_rate: 0.001 - batch_size: 64 - training_examples: 4499 - classes: 4\n",
            "Epoch 0/10 - 0.87s - loss: 93.51379 - acc: 0.4838581 - batches: 71\n",
            "Epoch 1/10 - 0.34s - loss: 91.20874 - acc: 0.5130992 - batches: 71\n",
            "Epoch 2/10 - 0.32s - loss: 91.125656 - acc: 0.5206885 - batches: 71\n",
            "Epoch 3/10 - 0.29s - loss: 89.788895 - acc: 0.5241189 - batches: 71\n",
            "Epoch 4/10 - 0.27s - loss: 88.48932 - acc: 0.5276316 - batches: 71\n",
            "Epoch 5/10 - 0.27s - loss: 88.01813 - acc: 0.53231907 - batches: 71\n",
            "Epoch 6/10 - 0.27s - loss: 87.811005 - acc: 0.5341048 - batches: 71\n",
            "Epoch 7/10 - 0.29s - loss: 87.71872 - acc: 0.5376762 - batches: 71\n",
            "Epoch 8/10 - 0.27s - loss: 87.64678 - acc: 0.5399084 - batches: 71\n",
            "Epoch 9/10 - 0.28s - loss: 87.587204 - acc: 0.5434798 - batches: 71\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH3CtC44J_qT",
        "outputId": "1781d416-579a-424e-ca97-7da3aa1b2639"
      },
      "source": [
        "# Evaluate model on test set\n",
        "biobert_med_df = biobert_med_pipelineModel.transform(testDataset).select('label', 'text', 'class.result').toPandas()\n",
        "biobert_med_df['result'] = biobert_med_df['result'].apply(lambda x: str(x[0])).replace(labelDict)\n",
        "print(classification_report(biobert_med_df.label, biobert_med_df.result))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Internal Medicine       0.36      0.24      0.29       109\n",
            "  Medical Records       0.40      0.68      0.50       102\n",
            "            Other       0.00      0.00      0.00        91\n",
            "          Surgery       0.62      0.80      0.70       198\n",
            "\n",
            "         accuracy                           0.51       500\n",
            "        macro avg       0.34      0.43      0.37       500\n",
            "     weighted avg       0.41      0.51      0.44       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFqQnRAEjUnu"
      },
      "source": [
        "## ML Classifiers with Sentence Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiMSeY7c2coT"
      },
      "source": [
        "### Logistic Regression with Universal Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRvZjR6Y2e4x"
      },
      "source": [
        "embeddings_finisher = EmbeddingsFinisher() \\\n",
        "      .setInputCols([\"sentence_embeddings\"]) \\\n",
        "      .setOutputCols([\"finished_embeddings\"]) \\\n",
        "      .setOutputAsVector(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"label\", outputCol = \"class\")\n",
        "\n",
        "ml_pipeline = Pipeline(\n",
        "      stages=[\n",
        "        document,\n",
        "        use,\n",
        "        embeddings_finisher,\n",
        "        label_stringIdx]\n",
        "      )"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--lJx2Je22FF"
      },
      "source": [
        "# Fit pipeline to train and test sets\n",
        "ml_model = ml_pipeline.fit(trainDataset)\n",
        "ml_train = ml_model.transform(trainDataset)\n",
        "ml_test = ml_model.transform(testDataset)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yDcN2El3jl-"
      },
      "source": [
        "# Explode sentence embeddings for train and test sets\n",
        "ml_train = ml_train.withColumn(\"features\", explode(ml_train.finished_embeddings))\n",
        "ml_test = ml_test.withColumn(\"features\", explode(ml_test.finished_embeddings))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72EWTF-431cP"
      },
      "source": [
        "# Fit logreg\n",
        "lr = LogisticRegression(labelCol=\"class\", maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "lrModel = lr.fit(ml_train)\n",
        "\n",
        "# Get test set preds\n",
        "lrPredictions = lrModel.transform(ml_test)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHRuxNj_4S62",
        "outputId": "cf57217e-fc40-4993-d697-78e3f1859445"
      },
      "source": [
        "# Evaluate performance\n",
        "logreg_df = lrPredictions.select('text','label','class','prediction').toPandas()\n",
        "print(classification_report(logreg_df[\"class\"], logreg_df.prediction))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.70      0.68       198\n",
            "         1.0       0.41      0.53      0.46       102\n",
            "         2.0       0.39      0.28      0.32       109\n",
            "         3.0       0.40      0.36      0.38        91\n",
            "\n",
            "    accuracy                           0.51       500\n",
            "   macro avg       0.47      0.47      0.46       500\n",
            "weighted avg       0.50      0.51      0.50       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTAImbASBT-L"
      },
      "source": [
        "### Random Forest with Universal Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcL2Ta9bBWRF"
      },
      "source": [
        "rf = RandomForestClassifier(labelCol=\"class\", \\\n",
        "                            featuresCol=\"features\", \\\n",
        "                            numTrees = 100, \\\n",
        "                            maxDepth = 4, \\\n",
        "                            maxBins = 32)\n",
        "\n",
        "# Train model with Training Data, get predictions on test set\n",
        "rfModel = rf.fit(ml_train)\n",
        "predictions_rf = rfModel.transform(ml_test)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxI0Y7HrdpuQ",
        "outputId": "45148000-23bd-4de6-8b96-ebb19c13382a"
      },
      "source": [
        "# Evaluate performance\n",
        "rf_df = predictions_rf.select(\"class\", \"prediction\").toPandas()\n",
        "print(classification_report(rf_df[\"class\"], rf_df.prediction))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.87      0.73       198\n",
            "         1.0       0.42      0.85      0.56       102\n",
            "         2.0       0.14      0.01      0.02       109\n",
            "         3.0       0.50      0.08      0.13        91\n",
            "\n",
            "    accuracy                           0.54       500\n",
            "   macro avg       0.42      0.45      0.36       500\n",
            "weighted avg       0.46      0.54      0.43       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWnTJGB2APJP"
      },
      "source": [
        "## ML Classifiers with Feature Vectorization Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir9O7ty6AYO0"
      },
      "source": [
        "### Logistic Regression with CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQgoftVwAXIC"
      },
      "source": [
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "      \n",
        "normalizer = Normalizer() \\\n",
        "      .setInputCols([\"token\"]) \\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "stemmer = Stemmer() \\\n",
        "      .setInputCols([\"cleanTokens\"]) \\\n",
        "      .setOutputCol(\"stem\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "      .setInputCols([\"stem\"]) \\\n",
        "      .setOutputCols([\"token_features\"]) \\\n",
        "      .setOutputAsArray(True) \\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "countVectors = CountVectorizer(inputCol=\"token_features\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
        "\n",
        "nlp_pipeline = Pipeline(\n",
        "    stages=[document, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            countVectors,\n",
        "            label_stringIdx])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rd0BvVEBnJS"
      },
      "source": [
        "# Fit pipeline to train and test set\n",
        "nlp_model = nlp_pipeline.fit(trainDataset)\n",
        "countvec_train = nlp_model.transform(trainDataset)\n",
        "countvec_test = nlp_model.transform(testDataset)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI1tTTy2Bm9Y",
        "outputId": "8b96b387-5a6e-481f-cdc2-98ffab38260e"
      },
      "source": [
        "countvec_train.printSchema()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- normalized: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- cleanTokens: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- stem: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token_features: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- class: double (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcsgl1onEtHQ"
      },
      "source": [
        "# Fit logreg\n",
        "lr = LogisticRegression(labelCol=\"class\", maxIter=10, regParam=0.3, elasticNetParam=0)\n",
        "lrModel = lr.fit(countvec_train)\n",
        "\n",
        "# Get test set preds\n",
        "lrPredictions = lrModel.transform(countvec_test)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck9yaatTEtHQ",
        "outputId": "be2e216c-5555-4b38-a477-4d61996cfad8"
      },
      "source": [
        "# Evaluate performance\n",
        "logreg_df = lrPredictions.select('text','label','class','prediction').toPandas()\n",
        "print(classification_report(logreg_df[\"class\"], logreg_df.prediction))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.63      0.61       198\n",
            "         1.0       0.23      0.26      0.24       102\n",
            "         2.0       0.23      0.19      0.21       109\n",
            "         3.0       0.23      0.21      0.22        91\n",
            "\n",
            "    accuracy                           0.38       500\n",
            "   macro avg       0.32      0.32      0.32       500\n",
            "weighted avg       0.38      0.38      0.38       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED81TpQCBC77"
      },
      "source": [
        "### Logistic Regression with TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9ebRhYCBoKq"
      },
      "source": [
        "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "\n",
        "nlp_pipeline_tf = Pipeline(\n",
        "    stages=[document, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            hashingTF,\n",
        "            idf,\n",
        "            label_stringIdx])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJUbN7N7BoIf"
      },
      "source": [
        "# Fit pipeline to train and test set\n",
        "tfidf_model = nlp_pipeline_tf.fit(trainDataset)\n",
        "tfidf_train = tfidf_model.transform(trainDataset)\n",
        "tfidf_test = tfidf_model.transform(testDataset)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RgDCXM0Bpwp"
      },
      "source": [
        "# Fit logreg\n",
        "lr = LogisticRegression(labelCol=\"class\", maxIter=10, regParam=0.3, elasticNetParam=0)\n",
        "lrModel_tf = lr.fit(tfidf_train)\n",
        "\n",
        "# Get test set preds\n",
        "lrPredictions_tf = lrModel_tf.transform(tfidf_test)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evPCQbemBqnn",
        "outputId": "6b02500f-7438-48f1-a03d-8e7da5adfa04"
      },
      "source": [
        "# Evaluate performance\n",
        "logreg_tf_df = lrPredictions_tf.select('class','prediction').toPandas()\n",
        "print(classification_report(logreg_tf_df[\"class\"], logreg_tf_df.prediction))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.58      0.60      0.59       198\n",
            "         1.0       0.25      0.31      0.28       102\n",
            "         2.0       0.16      0.12      0.14       109\n",
            "         3.0       0.20      0.20      0.20        91\n",
            "\n",
            "    accuracy                           0.36       500\n",
            "   macro avg       0.30      0.31      0.30       500\n",
            "weighted avg       0.35      0.36      0.36       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcG8DwQxbyVQ"
      },
      "source": [
        "### Random Forest with CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP381v3ub1k0"
      },
      "source": [
        "rf = RandomForestClassifier(labelCol=\"class\", \\\n",
        "                            featuresCol=\"features\", \\\n",
        "                            numTrees = 100, \\\n",
        "                            maxDepth = 4, \\\n",
        "                            maxBins = 32)\n",
        "\n",
        "# Train model and get predictions on test set\n",
        "rfModel_cv = rf.fit(countvec_train)\n",
        "predictions_rf_cv = rfModel_cv.transform(countvec_test)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6_FLDG0b7u3",
        "outputId": "8daf5db5-344b-4baf-8b5e-866d789faff3"
      },
      "source": [
        "# Evaluate performance\n",
        "rf_cv_df = predictions_rf_cv.select(\"class\", \"prediction\").toPandas()\n",
        "print(classification_report(rf_cv_df[\"class\"], rf_cv_df.prediction))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.86      0.75       198\n",
            "         1.0       0.41      0.98      0.58       102\n",
            "         2.0       1.00      0.01      0.02       109\n",
            "         3.0       0.00      0.00      0.00        91\n",
            "\n",
            "    accuracy                           0.54       500\n",
            "   macro avg       0.52      0.46      0.34       500\n",
            "weighted avg       0.56      0.54      0.42       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAfirCbhBVh5"
      },
      "source": [
        "### Random Forest with TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySBauV9GBXpO"
      },
      "source": [
        "# Train model and get predictions on test set\n",
        "rfModel_tf = rf.fit(tfidf_train)\n",
        "predictions_rf_tf = rfModel_tf.transform(tfidf_test)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESdOD7WkBpdX",
        "outputId": "bff62853-63c1-47c2-e92d-b9600fd0ab6a"
      },
      "source": [
        "# Evaluate performance\n",
        "rf_tf_df = predictions_rf_tf.select(\"class\", \"prediction\").toPandas()\n",
        "print(classification_report(rf_tf_df[\"class\"], rf_tf_df.prediction))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.87      0.75       198\n",
            "         1.0       0.40      0.92      0.56       102\n",
            "         2.0       0.00      0.00      0.00       109\n",
            "         3.0       0.00      0.00      0.00        91\n",
            "\n",
            "    accuracy                           0.53       500\n",
            "   macro avg       0.26      0.45      0.33       500\n",
            "weighted avg       0.34      0.53      0.41       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-TFsFwsmS5x"
      },
      "source": [
        "## Conclusion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMX7HSA9f0Qa"
      },
      "source": [
        "To compare the performance of the different models and account for the class imbalance, we can focus on the weighted average of the F1 score. The top 3 performing models were:\n",
        "\n",
        "1. Logistic Regression with Universal Sentence Encoder (0.50)\n",
        "2. DL Classification with BERT Sentence Embeddings (0.45)\n",
        "3. DL Classification with BioBERT Clnical Sentence Embeddings (0.45)\n",
        "\n",
        "All models performed poorly overall possibly due to the small sample size and class imbalances."
      ]
    }
  ]
}